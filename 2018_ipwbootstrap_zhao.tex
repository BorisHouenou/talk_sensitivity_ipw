\documentclass{beamer}
\usetheme{metropolis}

\usepackage[english]{babel}
\usepackage[utf8x]{inputenc}

\usepackage{amstext}
%\usepackage{coloremoji}
\usepackage{layout}
\usepackage{multirow}

\usepackage{graphicx}
\graphicspath{ {figs/} }

\setbeameroption{hide notes}
\setbeamertemplate{note page}[plain]
\usepackage{listings}
\usepackage{datetime}
\usepackage{url}

% specifications for presenter mode
%\beamerdefaultoverlayspecification{<+->}
%\setbeamercovered{transparent}

% math shorthand
\usepackage{bm}
\usepackage{amsmath}
\usepackage{mathtools}
\newcommand{\R}{\mathbb{R}}
\newcommand{\D}{\mathcal{D}}
\newcommand{\E}{\mathbb{E}}
\newcommand{\pr}{\mathbb{P}}
\newcommand{\F}{\mathcal{F}}
\newcommand{\X}{\mathcal{X}}
\newcommand{\lik}{\mathcal{L}}
\DeclarePairedDelimiterX{\infdivx}[2]{(}{)}{%
  #1\;\delimsize\|\;#2%
}
\newcommand{\infdiv}{D\infdivx}
\DeclarePairedDelimiter{\norm}{\lVert}{\rVert}
\DeclareMathOperator*{\argmin}{arg\,min}
\DeclareMathOperator*{\argmax}{arg\,max}

% indepndence notation macro
\newcommand\independent{\protect\mathpalette{\protect\independenT}{\perp}}
\def\independenT#1#2{\mathrel{\rlap{$#1#2$}\mkern2mu{#1#2}}}

% Bibliography
\usepackage{natbib}
\bibpunct{(}{)}{,}{a}{}{;}
\usepackage{bibentry}
%\nobibliography*

\title[ipw-bootstrap]{Sensitivity Analysis for Inverse Probability Weighting
  Estimators via the Percentile Bootstrap \small (Q.~Zhao, D.S.~Small, \&
  B.B.~Bhattacharya, 2017)}
\subtitle{\vspace*{0.5em} \scriptsize for ``Observational Study Design and
  Causal Inference'' (Statistics 260),\\ organized by S.~Pimentel, Spring 2018,
  University of California, Berkeley}
\author{Nima Hejazi}
\institute{Group in Biostatistics,\\ University of California, Berkeley\\
  \url{https://statistics.berkeley.edu/~nhejazi}
}
\date{12 April 2018}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\AtBeginSubsection[]{
\begin{frame}{Outline}
\tableofcontents[currentsection,currentsubsection]
\end{frame}
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{document}

\begin{frame}
  \titlepage
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Introduction}
\subsection{Preliminaries}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}{Preliminaries: Notation}

\begin{itemize}
  \itemsep12pt
  \item Data: $(A_1, \bm{X_1}, Y_1), \ldots, (A_n, \bm{X_n}, Y_n)
    \stackrel{\text{iid}}{\sim} F_0$, for a (binary) treatment $A_i$ and
    measured confounders $\bm{X_i}$.
  \item Outcome: $Y_i = A_iY_i(1) + (1 - A_i)Y_i(0)$, using potential outcome
    notation.
  \item Estimand (Parameter): $\Delta \coloneqq \E_0[Y(1)] - \E_0[Y(0)]$\\
    (average treatment effect)
\end{itemize}

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}{Preliminaries: Identifiability and Assumptions}

\begin{itemize}
  \itemsep12pt
  \item Stable Unit Treatment Value Assumption (SUTVA)
  \item No Unmeasured Confounders (NUC): $(Y(0), Y(1)) \independent A \mid
    \bm{X}$\\(strong ignorability)
  \item Overlap: $e_0(x) \coloneqq \pr_0(A = 1 \mid X = x) \in (0, 1)$\\
    (bounded propensity score)
\end{itemize}

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}{Preliminaries: IPW Estimators}

\begin{itemize}
  \itemsep12pt
  \item Inverse Probability of Weighting (IPW) Estimators:
    \[
      \hat{\Delta}_{\text{IPW}} = \frac{1}{n} \sum_{i = 1}^n
      \frac{A_iY_i}{\hat{e}(X_i)} - \frac{(1 - A_i)Y_i}{1 - \hat{e}(X_i)}
    \]
  \item $\hat{\Delta}$ consistently estimates $\Delta$ as long as
    $\hat{e}(\bm{X})$ converges to $e_0$.
\end{itemize}

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Objectives}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}{The Objective: Sensitivity Analysis}

\begin{itemize}
  \itemsep12pt
  \item Under violations of the NUC assumption, $\hat{\Delta}_{\text{IPW}}$ is
    biased and has a confidence interval that doesn't cover $\Delta$ properly.
  \item The goal of a sensitivity analysis is to gauge the degree to which a
    statistical inference is incorrect under violations of the NUC assumption.
    \begin{itemize}
      \itemsep6pt
      \item To what extent could the existence of potentially unmeasured
        confounders invalidate our findings?
      \item ...
    \end{itemize}
\end{itemize}

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}{The Objective: Sensitivity Analysis}

\begin{itemize}
  \itemsep12pt
  \item Under the NUC assumption, we have the following
    \[
      e_a(x,y) \coloneqq \pr_0(A = 1 \mid \bm{X} = x, Y(a) = y) = e_a(x),
    \]
    for $a \in \{0, 1\}$.
    \begin{itemize}
      \itemsep6pt
      \item $e_a(x,y)$ --- ``complete data'' selection probability.
      \item $e_a(x)$ --- ``observed data'' selection probability.
    \end{itemize}
  \item Thus, a sensitivity model might consider gauging whether $e_a(x,y) =
    e_a(x)$ holds in order to assess violations of NUC.
\end{itemize}

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Methodology}
\subsection{Sensitivity: Parameter, Analysis, Inference}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}{Sensitivity Parameter}

\begin{itemize}
  \itemsep12pt
  \item Marginal Sensitivity Model: let
    \[
      \mathcal{E}(\Lambda) = \left\{e(x,y): \frac{1}{\Lambda} \leq
      \text{OR}(e(x,y), e_0(x)) \leq \Lambda, x \in \mathcal{X}, y \in
      \R \right\}
    \]
  \item Then, for observational causal inference, let us assume that
    $e_a(x,y) \in \mathcal{E}(\Lambda),$ for $a \in \{0, 1\}$.
  \item ...
\end{itemize}

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}{Sensitivity Parameter}

\begin{itemize}
  \itemsep12pt
  \item For convenience, we'll use a logistic representation of the sensitivity
    model:
    \[ h_0(x,y) = g_0(x) - g_0(x,y),\]
    where
    \begin{itemize}
      \itemsep6pt
      \item $g_0(x)=\text{logit}(e_0(x))=\text{log}\frac{e_0(x)}{1-e_0(x)}$
      \item Similarly, let $g_0(x,y) = \text{logit}(e_0(x,y))$.
    \end{itemize}
  \item Then, we may express $\mathcal{E}(\Lambda)$ as
    \[\mathcal{E}(\Lambda) = \{e^{(h)}(x,y): h \in \mathcal{H}(\lambda)\},\]
    where $\mathcal{H}(\lambda) = \{h: \mathcal{X} \times \R \to \R$ and
    $\lVert h \rVert_{\infty} \leq \lambda\}$.
\end{itemize}

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}{Parametric Models in Sensitivity Analysis}

\begin{itemize}
  \itemsep12pt
  \item Ideally, $e_0(x)$ would be estimated nonparametrically, but, in many
    cases, we restrict ourselves to parametric models:
    \[
    \begin{aligned}
      e_{\beta_0}(x) =& \argmin_{\beta \in \Theta} \text{KL}(\pr_0(A = 1 \mid
      \bm{X} = x) \Vert \pr_{\beta}(A = 1 \mid \bm{X} = x))\\
      =& \argmax_{\beta \in \Theta} \E_0[A \cdot \text{log}e_{\beta}(X) +
      (1 - A) \cdot \text{log}(1 - e_{\beta}(x)) \mid \bm{X} = x]
    \end{aligned}
    \]
  \item As before, now have $e_0(x,y) \in \mathcal{E}_{\beta_0}(\Lambda)$, where
    \[\mathcal{E}_{\beta_0}(\Lambda) \coloneqq \left\{e(x,y): \frac{1}{\Lambda}
      \leq \text{OR}(e(x,y), e_{\beta_0}(x,y)) \leq \Lambda, x \in \mathcal{X},
      y \in \R \right\} \]
\end{itemize}

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}{Confidence Intervals in Sensitivity Analysis}

\begin{itemize}
  \itemsep12pt
  \item ...
  \item ...
\end{itemize}

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}{Confidence Intervals in Sensitivity Analysis}

\begin{itemize}
  \itemsep12pt
  \item ...
  \item ...
\end{itemize}

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Inverse Probability Weighting Estimators}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}{IPW Estimators}

\begin{itemize}
  \itemsep12pt
  \item ...
  \item ...
\end{itemize}

\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}{IPW Estimators}

\begin{itemize}
  \itemsep12pt
  \item ...
  \item ...
\end{itemize}

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}{IPW Estimators}

\begin{itemize}
  \itemsep12pt
  \item ...
  \item ...
\end{itemize}

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Percentile Bootstrap and Interval Construction}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}{Percentile Bootstrap}

\begin{itemize}
  \itemsep12pt
  \item ...
  \item ...
\end{itemize}

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}{Percentile Bootstrap}

\begin{itemize}
  \itemsep12pt
  \item ...
  \item ...
\end{itemize}

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}{Percentile Bootstrap}

\begin{itemize}
  \itemsep12pt
  \item ...
  \item ...
\end{itemize}

\end{frame}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}{IPW Sensitivity with Percentile Bootstrap}

\begin{itemize}
  \itemsep12pt
  \item ...
  \item ...
\end{itemize}

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}{IPW Sensitivity with Percentile Bootstrap}

\begin{itemize}
  \itemsep12pt
  \item ...
  \item ...
\end{itemize}

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}{IPW Sensitivity with Percentile Bootstrap}

\begin{itemize}
  \itemsep12pt
  \item ...
  \item ...
\end{itemize}

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}{Extensions: Augmented IPW Estimators}

\begin{itemize}
  \itemsep12pt
  \item ...
  \item ...
\end{itemize}

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}{Extensions: Lipschitz Bounds in the Sensitivity Model}

\begin{itemize}
  \itemsep12pt
  \item ...
  \item ...
\end{itemize}

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Conclusions}
\subsection{Comparisons}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}{Comparison with Rosenbaum Sensitivity}

\begin{itemize}
  \itemsep12pt
  \item ...
  \item ...
\end{itemize}

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}{Comparison with Rosenbaum Sensitivity}

\begin{itemize}
  \itemsep12pt
  \item ...
  \item ...
\end{itemize}

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Review}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}{Review}

\begin{itemize}
  \itemsep12pt
  \item ...
  \item ...
\end{itemize}

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}{Review}

\begin{itemize}
  \itemsep12pt
  \item ...
  \item ...
\end{itemize}

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% don't want dimming with references
\setbeamercovered{}
\beamerdefaultoverlayspecification{}

\begin{frame}[c,allowframebreaks]{References}

\small
\bibliographystyle{plainnat}
\nocite{*}
\bibliography{refs}
\itemize

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\end{document}

